1,2- abstract (ENG-HUN)
2- Table of Content
3- Introduction (longer than paper)
		- introduce problems concepts from fingerspelling
		- different tasks from prev paper
(5+) - Related work
		- from paper
		- previous work (images?)
			- proposed architecture...
		- new papers
			- better mediapipe: https://arxiv.org/abs/2308.09525

(5+) - Graph Neural Networks (leave out GATv2 for start)
(5+) - Proposed Methodology
		- Intuitive problem with previous embedding (explain previous embedding also)
			- pos embedding etc explained with great visuals
		- New approach
			- possible masking of encoder input
			- Graph-based
				- challenges of representation of sequences (optimality of graph libraries)
				- technical details of GNNs (special mini batching etc...)
(2+)- Static fingerspelling
	- ds (new approach maybe)
	- old model vs new model (size, processing speed, training time)
	- results -> high hopes for the sequential prediction
		- !!!compare x,y,z vs x,y | GCN and GAT and GATv2 |  sizes
(3+) - Sequential model
	- new dataset/approach (explain smaller-bigger data etc...)
	- Throughout evaluation with charts and different model sizes
	- compare speed (effects of seq length)
	- export final results to appendix
1 - Conclusion/Future Work
	- Experiment with missing point representation (graph superior)
	- Faster GNN embedding
	- better mediapipe
	- look at citations
	- reverse task to generate new data (https://openaccess.thecvf.com/content/CVPR2023/html/Arkushin_Ham2Pose_Animating_Sign_Language_Notation_Into_Pose_Sequences_CVPR_2023_paper.html)
2 - Bibliography!