{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9632205,"sourceType":"datasetVersion","datasetId":5880542}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup\n\n","metadata":{}},{"cell_type":"code","source":"!python --version","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:47:45.171563Z","iopub.execute_input":"2024-10-20T20:47:45.171928Z","iopub.status.idle":"2024-10-20T20:47:46.195798Z","shell.execute_reply.started":"2024-10-20T20:47:45.171893Z","shell.execute_reply":"2024-10-20T20:47:46.194724Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Python 3.10.14\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:47:46.941521Z","iopub.execute_input":"2024-10-20T20:47:46.942451Z","iopub.status.idle":"2024-10-20T20:48:00.803075Z","shell.execute_reply.started":"2024-10-20T20:47:46.942409Z","shell.execute_reply":"2024-10-20T20:48:00.802139Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.5)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.6.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.8.30)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport math\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nseed = 42\ntorch.manual_seed(seed)\nprint(f\"torch version: {torch.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:01.010706Z","iopub.execute_input":"2024-10-20T20:48:01.011069Z","iopub.status.idle":"2024-10-20T20:48:05.362205Z","shell.execute_reply.started":"2024-10-20T20:48:01.011034Z","shell.execute_reply":"2024-10-20T20:48:05.361302Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"torch version: 2.4.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset\n\nFor details about the dataset see `data_handling.ipynb`","metadata":{}},{"cell_type":"code","source":"SAVE_FOLDER = \"../input/tdk-v2\"\nSEQ_LEN = 128\ndata_file_path = os.path.join(SAVE_FOLDER, f\"data_{SEQ_LEN}.pkl\")\nmeta_file_path = os.path.join(SAVE_FOLDER, f\"metadata_{SEQ_LEN}.csv\")\n\ndf = pd.read_pickle(data_file_path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:07.359221Z","iopub.execute_input":"2024-10-20T20:48:07.360230Z","iopub.status.idle":"2024-10-20T20:48:10.276147Z","shell.execute_reply.started":"2024-10-20T20:48:07.360188Z","shell.execute_reply":"2024-10-20T20:48:10.275181Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"             x_dominant_hand_0  x_dominant_hand_1  x_dominant_hand_2  \\\nsequence_id                                                            \n1816796431            0.408832           0.519912           0.612159   \n1816796431            0.398663           0.523662           0.638807   \n1816796431            0.419290           0.509726           0.593165   \n1816796431            0.398764           0.498118           0.583356   \n1816796431            0.420213           0.495650           0.571790   \n\n             x_dominant_hand_3  x_dominant_hand_4  x_dominant_hand_5  \\\nsequence_id                                                            \n1816796431            0.707576           0.797313           0.494709   \n1816796431            0.744236           0.832567           0.538486   \n1816796431            0.685492           0.777913           0.483669   \n1816796431            0.677779           0.775966           0.481279   \n1816796431            0.659049           0.749740           0.485707   \n\n             x_dominant_hand_6  x_dominant_hand_7  x_dominant_hand_8  \\\nsequence_id                                                            \n1816796431            0.532817           0.553556           0.566219   \n1816796431            0.564302           0.581011           0.597674   \n1816796431            0.510993           0.536410           0.564583   \n1816796431            0.491659           0.524974           0.571944   \n1816796431            0.475930           0.501727           0.539150   \n\n             x_dominant_hand_9  ...  z_dominant_hand_11  z_dominant_hand_12  \\\nsequence_id                     ...                                           \n1816796431            0.391196  ...           -0.245855           -0.269148   \n1816796431            0.441541  ...           -0.370770           -0.408097   \n1816796431            0.393016  ...           -0.285770           -0.318548   \n1816796431            0.412262  ...           -0.235725           -0.267054   \n1816796431            0.438294  ...           -0.186706           -0.217181   \n\n             z_dominant_hand_13  z_dominant_hand_14  z_dominant_hand_15  \\\nsequence_id                                                               \n1816796431            -0.129743           -0.251501           -0.278687   \n1816796431            -0.185217           -0.325494           -0.343373   \n1816796431            -0.155317           -0.274822           -0.312119   \n1816796431            -0.141380           -0.219369           -0.256553   \n1816796431            -0.107740           -0.165642           -0.201059   \n\n             z_dominant_hand_16  z_dominant_hand_17  z_dominant_hand_18  \\\nsequence_id                                                               \n1816796431            -0.266530           -0.152852           -0.257519   \n1816796431            -0.328294           -0.203126           -0.315719   \n1816796431            -0.316411           -0.181363           -0.286298   \n1816796431            -0.273690           -0.170996           -0.240285   \n1816796431            -0.222898           -0.131329           -0.183113   \n\n             z_dominant_hand_19  z_dominant_hand_20  \nsequence_id                                          \n1816796431            -0.275822           -0.266876  \n1816796431            -0.326104           -0.314282  \n1816796431            -0.316182           -0.322671  \n1816796431            -0.266193           -0.278110  \n1816796431            -0.208774           -0.225284  \n\n[5 rows x 63 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x_dominant_hand_0</th>\n      <th>x_dominant_hand_1</th>\n      <th>x_dominant_hand_2</th>\n      <th>x_dominant_hand_3</th>\n      <th>x_dominant_hand_4</th>\n      <th>x_dominant_hand_5</th>\n      <th>x_dominant_hand_6</th>\n      <th>x_dominant_hand_7</th>\n      <th>x_dominant_hand_8</th>\n      <th>x_dominant_hand_9</th>\n      <th>...</th>\n      <th>z_dominant_hand_11</th>\n      <th>z_dominant_hand_12</th>\n      <th>z_dominant_hand_13</th>\n      <th>z_dominant_hand_14</th>\n      <th>z_dominant_hand_15</th>\n      <th>z_dominant_hand_16</th>\n      <th>z_dominant_hand_17</th>\n      <th>z_dominant_hand_18</th>\n      <th>z_dominant_hand_19</th>\n      <th>z_dominant_hand_20</th>\n    </tr>\n    <tr>\n      <th>sequence_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1816796431</th>\n      <td>0.408832</td>\n      <td>0.519912</td>\n      <td>0.612159</td>\n      <td>0.707576</td>\n      <td>0.797313</td>\n      <td>0.494709</td>\n      <td>0.532817</td>\n      <td>0.553556</td>\n      <td>0.566219</td>\n      <td>0.391196</td>\n      <td>...</td>\n      <td>-0.245855</td>\n      <td>-0.269148</td>\n      <td>-0.129743</td>\n      <td>-0.251501</td>\n      <td>-0.278687</td>\n      <td>-0.266530</td>\n      <td>-0.152852</td>\n      <td>-0.257519</td>\n      <td>-0.275822</td>\n      <td>-0.266876</td>\n    </tr>\n    <tr>\n      <th>1816796431</th>\n      <td>0.398663</td>\n      <td>0.523662</td>\n      <td>0.638807</td>\n      <td>0.744236</td>\n      <td>0.832567</td>\n      <td>0.538486</td>\n      <td>0.564302</td>\n      <td>0.581011</td>\n      <td>0.597674</td>\n      <td>0.441541</td>\n      <td>...</td>\n      <td>-0.370770</td>\n      <td>-0.408097</td>\n      <td>-0.185217</td>\n      <td>-0.325494</td>\n      <td>-0.343373</td>\n      <td>-0.328294</td>\n      <td>-0.203126</td>\n      <td>-0.315719</td>\n      <td>-0.326104</td>\n      <td>-0.314282</td>\n    </tr>\n    <tr>\n      <th>1816796431</th>\n      <td>0.419290</td>\n      <td>0.509726</td>\n      <td>0.593165</td>\n      <td>0.685492</td>\n      <td>0.777913</td>\n      <td>0.483669</td>\n      <td>0.510993</td>\n      <td>0.536410</td>\n      <td>0.564583</td>\n      <td>0.393016</td>\n      <td>...</td>\n      <td>-0.285770</td>\n      <td>-0.318548</td>\n      <td>-0.155317</td>\n      <td>-0.274822</td>\n      <td>-0.312119</td>\n      <td>-0.316411</td>\n      <td>-0.181363</td>\n      <td>-0.286298</td>\n      <td>-0.316182</td>\n      <td>-0.322671</td>\n    </tr>\n    <tr>\n      <th>1816796431</th>\n      <td>0.398764</td>\n      <td>0.498118</td>\n      <td>0.583356</td>\n      <td>0.677779</td>\n      <td>0.775966</td>\n      <td>0.481279</td>\n      <td>0.491659</td>\n      <td>0.524974</td>\n      <td>0.571944</td>\n      <td>0.412262</td>\n      <td>...</td>\n      <td>-0.235725</td>\n      <td>-0.267054</td>\n      <td>-0.141380</td>\n      <td>-0.219369</td>\n      <td>-0.256553</td>\n      <td>-0.273690</td>\n      <td>-0.170996</td>\n      <td>-0.240285</td>\n      <td>-0.266193</td>\n      <td>-0.278110</td>\n    </tr>\n    <tr>\n      <th>1816796431</th>\n      <td>0.420213</td>\n      <td>0.495650</td>\n      <td>0.571790</td>\n      <td>0.659049</td>\n      <td>0.749740</td>\n      <td>0.485707</td>\n      <td>0.475930</td>\n      <td>0.501727</td>\n      <td>0.539150</td>\n      <td>0.438294</td>\n      <td>...</td>\n      <td>-0.186706</td>\n      <td>-0.217181</td>\n      <td>-0.107740</td>\n      <td>-0.165642</td>\n      <td>-0.201059</td>\n      <td>-0.222898</td>\n      <td>-0.131329</td>\n      <td>-0.183113</td>\n      <td>-0.208774</td>\n      <td>-0.225284</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 63 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"metadata_df = pd.read_csv(meta_file_path, header=0)\n\nmax_phrase_len = max([len(it) for it in metadata_df.phrase.values])\npossible_characters = sorted(set.union(*[set(p) for p in metadata_df.phrase.values]))\ntoken_map = {c: i+3 for i, c in enumerate(possible_characters)}\nPADDING = 'P'\nSOS = '<'\nEOS = '>'\ntoken_map[PADDING] = 0 # padding\ntoken_map[SOS] = 1 # SOS\ntoken_map[EOS] = 2 # EOS\nmetadata_df.phrase = metadata_df.phrase.apply(lambda it: np.array([token_map[c] for c in '<'+it+'>'+('P'*(max_phrase_len-len(it)))], dtype=np.int32))\nmax_phrase_len_with_sequence_control_tokens = max_phrase_len + 2 # SOS, EOS\n\n# Shuffle dataset\nmetadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n\nindex = {row[0]: {\"phrase\": row[1], \"signer_id\": row[2]} for row in metadata_df.to_numpy()}\nstr(index)[:100] + \"...\"","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:12.515450Z","iopub.execute_input":"2024-10-20T20:48:12.515805Z","iopub.status.idle":"2024-10-20T20:48:14.673001Z","shell.execute_reply.started":"2024-10-20T20:48:12.515773Z","shell.execute_reply":"2024-10-20T20:48:14.672036Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"{793258456: {'phrase': array([ 1, 16, 25, 14, 38,  3, 26, 16, 29, 21, 18, 31, 32, 28, 27,  2,  0,\\n  ...\""},"metadata":{}}]},{"cell_type":"code","source":"class TransformerDataset(torch.utils.data.Dataset):\n    def __init__(self, df, meta_data):\n        self.df = df\n        self.meta_data = meta_data\n        self.sequence_ids = df.index.unique()\n        self.padding_value = 0.0\n        self.seq_len = SEQ_LEN\n\n    def __len__(self):\n        return len(self.sequence_ids)\n\n    def __getitem__(self, idx):\n        sequence_id = self.sequence_ids[idx]\n        x_values = torch.tensor(self.df.loc[sequence_id].values, dtype=torch.float32)\n\n        x_mask = torch.ones(self.seq_len, dtype=torch.float32)\n\n        # Apply padding if the sequence is shorter than seq_len\n        if x_values.shape[0] < self.seq_len:\n            x_mask[x_values.shape[0]:] = token_map[PADDING]\n            padding_size = self.seq_len - x_values.shape[0]\n            padding = torch.full((padding_size, x_values.shape[1]), self.padding_value)\n            x_values = torch.cat([x_values, padding], dim=0)\n        elif x_values.shape[0] > self.seq_len:\n            # Truncate the sequence if it's longer than seq_len\n            x_values = x_values[:self.seq_len]\n\n        y_phrase = self.meta_data[sequence_id]['phrase']\n        return x_values, x_mask, y_phrase\n\ndataset = TransformerDataset(df, index)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:16.745844Z","iopub.execute_input":"2024-10-20T20:48:16.746577Z","iopub.status.idle":"2024-10-20T20:48:16.803999Z","shell.execute_reply.started":"2024-10-20T20:48:16.746536Z","shell.execute_reply":"2024-10-20T20:48:16.803020Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset.__getitem__(0)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:17.501916Z","iopub.execute_input":"2024-10-20T20:48:17.502530Z","iopub.status.idle":"2024-10-20T20:48:17.610901Z","shell.execute_reply.started":"2024-10-20T20:48:17.502484Z","shell.execute_reply":"2024-10-20T20:48:17.609963Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 0.4088,  0.5199,  0.6122,  ..., -0.2575, -0.2758, -0.2669],\n         [ 0.3987,  0.5237,  0.6388,  ..., -0.3157, -0.3261, -0.3143],\n         [ 0.4193,  0.5097,  0.5932,  ..., -0.2863, -0.3162, -0.3227],\n         ...,\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]),\n tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0.]),\n array([ 1,  7,  3, 16, 31, 18, 18, 24, 21, 28, 34, 32, 18,  2,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       dtype=int32))"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import random_split, DataLoader\n\nBATCH_SIZE = 32\n\n# Split lengths for train (80%), test (10%), valid (10%)\ntrain_size = int(0.8 * len(dataset))\nvalid_size = int(0.1 * len(dataset))\ntest_size = len(dataset) - train_size - valid_size\n\ntrain_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n\n# NOTE Keep num_workers=0\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n\nfor it in train_loader:\n    print(\"Shape of x:\")\n    print(it[0].shape)\n    print(\"\\nMask for input:\")\n    print(it[1].shape)\n    print(it[1])\n    print(\"\\nTarget:\")\n    print(it[2].shape)\n    print(it[2]) # NOTE dec inp: it[1][:, :-1], target: it[1][:, 1:]\n    break","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:18.648418Z","iopub.execute_input":"2024-10-20T20:48:18.648773Z","iopub.status.idle":"2024-10-20T20:48:18.704677Z","shell.execute_reply.started":"2024-10-20T20:48:18.648740Z","shell.execute_reply":"2024-10-20T20:48:18.703770Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Shape of x:\ntorch.Size([32, 128, 63])\n\nMask for input:\ntorch.Size([32, 128])\ntensor([[1., 1., 1.,  ..., 0., 0., 0.],\n        [1., 1., 1.,  ..., 0., 0., 0.],\n        [1., 1., 1.,  ..., 1., 1., 0.],\n        ...,\n        [1., 1., 1.,  ..., 0., 0., 0.],\n        [1., 1., 1.,  ..., 0., 0., 0.],\n        [1., 1., 1.,  ..., 0., 0., 0.]])\n\nTarget:\ntorch.Size([32, 33])\ntensor([[ 1,  9, 12,  ...,  0,  0,  0],\n        [ 1, 14, 17,  ...,  0,  0,  0],\n        [ 1,  5,  5,  ...,  0,  0,  0],\n        ...,\n        [ 1, 33, 14,  ...,  0,  0,  0],\n        [ 1, 10,  8,  ...,  0,  0,  0],\n        [ 1, 10,  5,  ...,  0,  0,  0]], dtype=torch.int32)\n","output_type":"stream"}]},{"cell_type":"code","source":"iterator = iter(train_loader)\n%timeit next(iterator)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:42.323388Z","iopub.execute_input":"2024-10-20T20:48:42.324127Z","iopub.status.idle":"2024-10-20T20:48:45.264387Z","shell.execute_reply.started":"2024-10-20T20:48:42.324084Z","shell.execute_reply":"2024-10-20T20:48:45.263262Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"36.2 ms ± 634 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Constructing the Transformer\n\nSources:\n\n- [correct `transformer implementation` from scratch in `pytorch`](https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb) (in-depth tutorial from same author: [part1](https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021), [part2](https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-2-bf2403804ada))\n- [nice visuals for understanding `multi-head attention`](http://jalammar.github.io/illustrated-transformer/)\n- [`positional encoding`](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)\n- [kaggle transformer code: ❗Contains mistakes (see comments), but nice overall explanation](https://www.kaggle.com/code/arunmohan003/transformer-from-scratch-using-pytorch)","metadata":{}},{"cell_type":"markdown","source":"## General Components","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        \n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        self.W_o = nn.Linear(d_model, d_model)\n        \n    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n        if mask is not None:\n            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n        attn_probs = torch.softmax(attn_scores, dim=-1)\n        output = torch.matmul(attn_probs, V)\n        return output\n        \n    def split_heads(self, x):\n        batch_size, seq_length, d_model = x.size()\n        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n        \n    def combine_heads(self, x):\n        batch_size, _, seq_length, d_k = x.size()\n        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n        \n    def forward(self, Q, K, V, mask=None):\n        Q = self.split_heads(self.W_q(Q))\n        K = self.split_heads(self.W_k(K))\n        V = self.split_heads(self.W_v(V))\n        \n        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n        output = self.W_o(self.combine_heads(attn_output))\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:49.697045Z","iopub.execute_input":"2024-10-20T20:48:49.697436Z","iopub.status.idle":"2024-10-20T20:48:49.711121Z","shell.execute_reply.started":"2024-10-20T20:48:49.697398Z","shell.execute_reply":"2024-10-20T20:48:49.710062Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_seq_len, n=10000):\n        super(PositionalEncoding, self).__init__()\n\n        assert d_model % 2 == 0, \"d_model must be even\"\n        \n        pe = torch.zeros(max_seq_len, d_model)\n        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(n) / d_model))\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n\n        # NOTE\n        # register buffer in Pytorch ->\n        # If you have parameters in your model, which should be saved and restored in the state_dict,\n        # but not trained by the optimizer, you should register them as buffers.\n        self.register_buffer('pe', pe.unsqueeze(0))\n        \n    def forward(self, x):\n        # Broadcasting mechanism (automatically works for multiple batches even when shapes don't match along batch dim)\n        return x + self.pe[:, :x.size(1)]","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:50.858568Z","iopub.execute_input":"2024-10-20T20:48:50.859435Z","iopub.status.idle":"2024-10-20T20:48:50.869770Z","shell.execute_reply.started":"2024-10-20T20:48:50.859375Z","shell.execute_reply":"2024-10-20T20:48:50.868762Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff):\n        super(FeedForward, self).__init__()\n        self.fc1 = nn.Linear(d_model, d_ff)\n        self.fc2 = nn.Linear(d_ff, d_model)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        return self.fc2(self.relu(self.fc1(x)))","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:51.631595Z","iopub.execute_input":"2024-10-20T20:48:51.632458Z","iopub.status.idle":"2024-10-20T20:48:51.639582Z","shell.execute_reply.started":"2024-10-20T20:48:51.632399Z","shell.execute_reply":"2024-10-20T20:48:51.638502Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Encoder Embeddings","metadata":{}},{"cell_type":"code","source":"class LandmarkEmbedding(nn.Module):\n    def __init__(self, d_model, num_features, num_conv_layers, filter_size):\n        super(LandmarkEmbedding, self).__init__()\n\n        self.d_model = d_model\n\n        first_conv = nn.Conv1d(in_channels=num_features, out_channels=d_model, kernel_size=filter_size, padding='same')\n        rest_of_convs = [\n            nn.Conv1d(in_channels=d_model, out_channels=d_model, kernel_size=filter_size, padding='same')\n            for _ in range(num_conv_layers-1)\n        ]\n        \n        self.conv_block = nn.Sequential(\n            first_conv, *rest_of_convs\n        )\n\n    def forward(self, x):\n        # x is expected to be of shape (batch_size, seq_len, num_of_features)\n        x = x.permute(0, 2, 1) # (batch_size, num_of_features, seq_len)\n        x = self.conv_block(x)\n        # TODO experiment with scaling the output\n        # x *= math.sqrt(self.d_model)\n        x = x.permute(0, 2, 1) # (batch_size, seq_len, d_model)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:48:53.633897Z","iopub.execute_input":"2024-10-20T20:48:53.634934Z","iopub.status.idle":"2024-10-20T20:48:53.644181Z","shell.execute_reply.started":"2024-10-20T20:48:53.634880Z","shell.execute_reply":"2024-10-20T20:48:53.643173Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"lm_embedding = LandmarkEmbedding(\n    d_model=128,\n    num_features=21*3, #num_nodes_per_hands*num_features_per_node\n    num_conv_layers=3,\n    filter_size=11\n)\n\n# Check parameter tensor shapes\nfor name, param in lm_embedding.named_parameters():\n    if param.requires_grad:\n        print(f\"Layer: {name} | Size: {param.size()}\")\n\n# Measure Performance\nx = next(iter(train_loader))[0]\n%timeit lm_embedding(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:49:55.980895Z","iopub.execute_input":"2024-10-20T20:49:55.981777Z","iopub.status.idle":"2024-10-20T20:50:09.578704Z","shell.execute_reply.started":"2024-10-20T20:49:55.981736Z","shell.execute_reply":"2024-10-20T20:50:09.577600Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Layer: conv_block.0.weight | Size: torch.Size([128, 63, 11])\nLayer: conv_block.0.bias | Size: torch.Size([128])\nLayer: conv_block.1.weight | Size: torch.Size([128, 128, 11])\nLayer: conv_block.1.bias | Size: torch.Size([128])\nLayer: conv_block.2.weight | Size: torch.Size([128, 128, 11])\nLayer: conv_block.2.bias | Size: torch.Size([128])\n15.8 ms ± 810 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n","output_type":"stream"}]},{"cell_type":"code","source":"from typing import Literal\n\nfrom torch_geometric.data import Data, Batch\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n\nclass MyGCNConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(MyGCNConv, self).__init__()\n        \n        self.conv = GCNConv(in_channels, out_channels)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x, edge_index):\n        x = self.conv(x, edge_index)\n        x = self.relu(x)\n        return x\n    \nclass MyGATConv(nn.Module):\n    def __init__(self, in_channels, out_channels, attention_heads):\n        super(MyGATConv, self).__init__()\n        \n        assert out_channels % attention_heads == 0\n        \n        self.conv = GATConv(in_channels, out_channels//attention_heads, heads=attention_heads, concat=True)\n        self.combine_heads = nn.Linear(out_channels, out_channels)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x, edge_index):\n        x = self.conv(x, edge_index)\n        x = self.combine_heads(x)\n        x = self.relu(x)\n        return x\n    \nclass MyGATv2Conv(MyGATConv):\n    def __init__(self, in_channels, out_channels, attention_heads):\n        super(MyGATv2Conv, self).__init__(in_channels, out_channels, attention_heads)\n        \n        # Replace the GATConv layer with GATv2Conv\n        self.conv = GATv2Conv(in_channels, out_channels // attention_heads, heads=attention_heads, concat=True)\n        \n\nclass GraphEmbedding(nn.Module):\n    def __init__(\n            self,\n            num_nodes: int,\n            num_features_per_node: int,\n            d_model: int,\n            hidden_dim: int,\n            seq_len: int,\n            batch_size: int,\n            layer_type: Literal[\"gcn_conv\", \"gat_conv\", \"gat_conv_v2\"],\n            num_layers: int,\n            attention_heads = None\n        ):\n        super(GraphEmbedding, self).__init__()\n        self.d_model = d_model\n        self.num_nodes = num_nodes\n        self.num_features_per_node = num_features_per_node\n        self.batch_size = batch_size\n        self.seq_len = seq_len\n        \n        assert num_layers >= 2\n        \n        if attention_heads:\n            assert hidden_dim % attention_heads == 0 and d_model % attention_heads == 0\n\n        if layer_type == \"gcn_conv\":\n            conv_layers = []\n            conv_layers.append(MyGCNConv(num_features_per_node, hidden_dim))\n            for i in range(1, num_layers):\n                conv_layers.append(MyGCNConv(hidden_dim, hidden_dim if i != num_layers-1 else d_model))\n            self.graph_conv = nn.ModuleList(conv_layers)\n        else:\n            conv_layers = []\n            conv_layer_class = MyGATConv if layer_type == \"gat_conv\" else MyGATv2Conv\n            conv_layers.append(conv_layer_class(num_features_per_node, hidden_dim, attention_heads))\n            for i in range(1, num_layers):\n                conv_layers.append(conv_layer_class(hidden_dim, hidden_dim if i != num_layers-1 else d_model, attention_heads))\n            self.graph_conv = nn.ModuleList(conv_layers)\n\n        # Precompute edge_index and batch_info for batch\n        # Based on: https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/loader/dataloader.py\n        connections = [\n            (0,1), (0,5), (0,17), (1,2), (2,3), (3,4),\n            (5,6), (5,9), (6,7), (7,8), (9,10), (9,13),\n            (10,11), (11,12), (13,14), (13,17), (14,15),\n            (15,16), (17,18), (18,19), (19,20)\n        ]\n        edges = []\n        for a, b in connections:\n            edges.append([a, b])\n            edges.append([b, a])  # Add the reverse connection\n        single_graph_edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n\n        # NOTE Edge index calculation can be done without using Batch.from_data_list(...) -> improve performance\n        # For a one time run this is good enough.\n        example_graph_features = torch.zeros(self.num_nodes, self.num_features_per_node)\n        data_list = [Data(x=example_graph_features, edge_index=single_graph_edge_index) for _ in range(self.batch_size*self.seq_len)]\n        mini_batch = Batch.from_data_list(data_list)\n\n        # This prevents prevents this layer to work with different batch sizes (TODO fix)\n        self.register_buffer('edge_index', mini_batch.edge_index)\n        self.register_buffer('batch_info', mini_batch.batch)\n\n    def forward(self, x):\n        # x ~ (batch_size, seq_len, num_features)\n        \n        x = x.reshape(-1, self.num_features_per_node) # (batch_size*seq_len*num_nodes, num_features_per_node)\n        \n        # Obtain node embeddings\n        for layer in self.graph_conv:\n            x = layer(x, self.edge_index)\n        \n        # Readout layer\n        x = global_mean_pool(x, self.batch_info)  # (batch_size*sequence_len, d_model)\n        \n        x = x.reshape(self.batch_size, self.seq_len, self.d_model)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:50:12.332361Z","iopub.execute_input":"2024-10-20T20:50:12.332707Z","iopub.status.idle":"2024-10-20T20:50:14.706801Z","shell.execute_reply.started":"2024-10-20T20:50:12.332674Z","shell.execute_reply":"2024-10-20T20:50:14.705876Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"graph_embedding = GraphEmbedding(\n    num_nodes=21,\n    num_features_per_node=3,\n    d_model=128,\n    hidden_dim=128,\n    seq_len=SEQ_LEN,\n    batch_size=BATCH_SIZE,\n    layer_type=\"gcn_conv\",\n    num_layers=3,\n    attention_heads=8\n)\n\n# Check parameter tensor shapes\nfor name, param in graph_embedding.named_parameters():\n    if param.requires_grad:\n        print(f\"Layer: {name} | Size: {param.size()}\")\n\n# Measure Performance\nx = next(iter(train_loader))[0]\n\n# NOTE This is slower than LandmarkEmbedding\n# ?!Rewrite GNN layers using the fact that all graphs will have the same structure\n\n# Run on GPU to make it faster\nx = x.to(\"cuda\")\ngraph_embedding.to(\"cuda\")\n\n%timeit graph_embedding(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:50:20.410029Z","iopub.execute_input":"2024-10-20T20:50:20.410849Z","iopub.status.idle":"2024-10-20T20:50:21.593928Z","shell.execute_reply.started":"2024-10-20T20:50:20.410808Z","shell.execute_reply":"2024-10-20T20:50:21.592914Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Layer: graph_conv.0.conv.bias | Size: torch.Size([128])\nLayer: graph_conv.0.conv.lin.weight | Size: torch.Size([128, 3])\nLayer: graph_conv.1.conv.bias | Size: torch.Size([128])\nLayer: graph_conv.1.conv.lin.weight | Size: torch.Size([128, 128])\nLayer: graph_conv.2.conv.bias | Size: torch.Size([128])\nLayer: graph_conv.2.conv.lin.weight | Size: torch.Size([128, 128])\n13 ms ± 72.9 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Rest of the Transformer","metadata":{}},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout):\n        super(EncoderLayer, self).__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.feed_forward = FeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, mask):\n        attn_output = self.self_attn(x, x, x, mask)\n        x = self.norm1(x + self.dropout(attn_output))\n        ff_output = self.feed_forward(x)\n        x = self.norm2(x + self.dropout(ff_output))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:50:36.925056Z","iopub.execute_input":"2024-10-20T20:50:36.925909Z","iopub.status.idle":"2024-10-20T20:50:36.932912Z","shell.execute_reply.started":"2024-10-20T20:50:36.925866Z","shell.execute_reply":"2024-10-20T20:50:36.931960Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout):\n        super(DecoderLayer, self).__init__()\n        self.masked_self_attn = MultiHeadAttention(d_model, num_heads)\n        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n        self.feed_forward = FeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        attn_output = self.masked_self_attn(x, x, x, tgt_mask)\n        x = self.norm1(x + self.dropout(attn_output))\n        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n        x = self.norm2(x + self.dropout(attn_output))\n        ff_output = self.feed_forward(x)\n        x = self.norm3(x + self.dropout(ff_output))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:50:38.114124Z","iopub.execute_input":"2024-10-20T20:50:38.114548Z","iopub.status.idle":"2024-10-20T20:50:38.123165Z","shell.execute_reply.started":"2024-10-20T20:50:38.114509Z","shell.execute_reply":"2024-10-20T20:50:38.122105Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(\n            self,\n            encoder_embedding: nn.Module,\n            tgt_vocab_size: int,\n            d_model: int,\n            num_heads: int,\n            num_enc_layers: int,\n            num_dec_layers: int,\n            d_ff: int,\n            max_seq_length: int,\n            dropout: float\n        ):\n        super(Transformer, self).__init__()\n\n        self.encoder_embedding = encoder_embedding\n        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n\n        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_enc_layers)])\n        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_dec_layers)])\n\n        self.fc = nn.Linear(d_model, tgt_vocab_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def generate_mask(self, src_mask, tgt):\n        src_mask = (src_mask != 0).unsqueeze(1).unsqueeze(2) # NOTE Here the src_mask contains ones and zeros\n        tgt_mask = (tgt != token_map[PADDING]).unsqueeze(1).unsqueeze(3)\n        seq_length = tgt.size(1)\n        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(tgt_mask.device)\n        tgt_mask = tgt_mask & nopeak_mask\n        return src_mask, tgt_mask\n\n    def forward(self, src, x_mask, tgt):\n        src_mask, tgt_mask = self.generate_mask(x_mask, tgt)\n        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n\n        enc_output = src_embedded\n        for enc_layer in self.encoder_layers:\n            enc_output = enc_layer(enc_output, src_mask)\n\n        dec_output = tgt_embedded\n        for dec_layer in self.decoder_layers:\n            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n\n        output = self.fc(dec_output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:54:26.865612Z","iopub.execute_input":"2024-10-20T20:54:26.866431Z","iopub.status.idle":"2024-10-20T20:54:26.878897Z","shell.execute_reply.started":"2024-10-20T20:54:26.866390Z","shell.execute_reply":"2024-10-20T20:54:26.877772Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Training Utils","metadata":{}},{"cell_type":"code","source":"# Source: https://github.com/jamfromouterspace/levenshtein\n\ndef levenshtein_distance(seq1, seq2):\n    len_1, len_2 = len(seq1), len(seq2)\n    dp = [[0] * (len_2 + 1) for _ in range(len_1 + 1)]\n\n    for i in range(len_1 + 1):\n        dp[i][0] = i\n    for j in range(len_2 + 1):\n        dp[0][j] = j\n\n    for i in range(1, len_1 + 1):\n        for j in range(1, len_2 + 1):\n            cost = 0 if seq1[i - 1] == seq2[j - 1] else 1\n            dp[i][j] = min(dp[i - 1][j] + 1,\n                           dp[i][j - 1] + 1,\n                           dp[i - 1][j - 1] + cost)\n\n    return dp[len_1][len_2]\n\nindices_to_ignore = torch.tensor([token_map[\" \"], token_map[\"<\"], token_map[\"P\"]]) # End of sequence is important\n\ndef masked_levenshtein(output_tokens, target_tokens):\n    batch_size = output_tokens.size(0)\n    total_distance = 0\n\n    for i in range(batch_size):\n        pred_seq = output_tokens[i].tolist()\n        target_seq = target_tokens[i].tolist()\n\n        # Find first occurrence of EOS in both sequences\n        pred_eos_idx = next((idx for idx, token in enumerate(pred_seq) if token == token_map[EOS]), len(pred_seq))\n        target_eos_idx = next((idx for idx, token in enumerate(target_seq) if token == token_map[EOS]), len(target_seq))\n\n        # Trim the sequences at the first EOS index\n        pred_trimmed = pred_seq[:pred_eos_idx]\n        target_trimmed = target_seq[:target_eos_idx]\n\n        # Compute Levenshtein distance for the trimmed sequences\n        total_distance += levenshtein_distance(pred_trimmed, target_trimmed)\n\n    # NOTE not sum of distances are returned!\n    return total_distance\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:54:28.130802Z","iopub.execute_input":"2024-10-20T20:54:28.131168Z","iopub.status.idle":"2024-10-20T20:54:28.142474Z","shell.execute_reply.started":"2024-10-20T20:54:28.131133Z","shell.execute_reply":"2024-10-20T20:54:28.141518Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# # Optional lr scheduling as in Attention Is All You Need\n# class LinearWarmupInverseSquarerootDecay(torch.optim.lr_scheduler.LambdaLR):\n#     def __init__(self, d_model, warmup_steps=4000, optimizer=None):\n#         self.d_model = d_model\n#         self.warmup_steps = warmup_steps\n#         super(LinearWarmupInverseSquarerootDecay, self).__init__(optimizer, self.lr_lambda)\n\n#     def lr_lambda(self, step_num):\n#         return (self.d_model ** -0.5) * min(step_num ** -0.5 if step_num != 0 else 1e20, step_num * (self.warmup_steps ** -1.5))\n    \n# steps = np.arange(0, 10000)\n# learning_rates = [scheduler.lr_lambda(step) for step in steps]\n\n# plt.figure(figsize=(6, 3))\n# plt.plot(steps, learning_rates, label='Learning Rate')\n# plt.title('Learning Rate Schedule')\n# plt.xlabel('Step Number')\n# plt.ylabel('Learning Rate')\n# plt.grid(True)\n# plt.legend()\n# plt.show()\n\n# scheduler = LinearWarmupInverseSquarerootDecay(d_model=d_model, optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:54:28.673308Z","iopub.execute_input":"2024-10-20T20:54:28.674076Z","iopub.status.idle":"2024-10-20T20:54:28.678534Z","shell.execute_reply.started":"2024-10-20T20:54:28.674037Z","shell.execute_reply":"2024-10-20T20:54:28.677632Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport zipfile\n\ndef eval_settings(settings: dict):\n    # Create model\n    encoder_embedding = LandmarkEmbedding(\n        d_model=settings[\"d_model\"],\n        num_features=settings[\"num_nodes_per_hand\"]*settings[\"num_features_per_node\"],\n        num_conv_layers=settings[\"embedding\"][\"num_conv_layers\"],\n        filter_size=settings[\"embedding\"][\"filter_size\"]\n    ) if settings[\"embedding\"][\"name\"] == \"landmark_embedding\" else GraphEmbedding(\n        num_nodes=settings[\"num_nodes_per_hand\"],\n        num_features_per_node=settings[\"num_features_per_node\"],\n        d_model=settings[\"d_model\"],\n        hidden_dim=settings[\"embedding\"][\"hidden_dim\"],\n        seq_len=settings[\"seq_len\"],\n        batch_size=settings[\"batch_size\"],\n        layer_type=settings[\"embedding\"][\"layer_type\"],\n        num_layers=settings[\"embedding\"][\"num_layers\"],\n        attention_heads=settings[\"embedding\"].get(\"attention_heads\")\n    )\n\n    transformer = Transformer(\n        encoder_embedding=encoder_embedding,\n        tgt_vocab_size = settings[\"tgt_vocab_size\"],\n        d_model=settings[\"d_model\"],\n        num_heads=settings[\"num_heads\"],\n        num_enc_layers=settings[\"num_enc_layer\"],\n        num_dec_layers=settings[\"num_dec_layer\"],\n        d_ff=settings[\"dff\"],\n        max_seq_length=max(settings[\"phrase_length\"], settings[\"seq_len\"]),\n        dropout=settings[\"dropout\"]\n    )\n    \n    # Use GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    transformer.to(device)\n    \n    # Run training\n    criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignoring padding\n    optimizer = torch.optim.Adam(transformer.parameters())\n    #optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0)\n    \n    # Helper\n    def run_epoch(loader, is_train=True):\n        epoch_loss = 0\n        total_correct = 0\n        total_tokens = 0\n        total_levenshtein_distance = 0\n\n        if is_train:\n            transformer.train()\n        else:\n            transformer.eval()\n\n        for batch in loader:\n            src_data, x_mask, tgt_data = batch\n            src_data = src_data.to(device)\n            x_mask = x_mask.to(device)\n            tgt_data = tgt_data.to(device)\n\n            optimizer.zero_grad()\n\n            # Disable gradient calculation during validation\n            with torch.set_grad_enabled(is_train):\n                output = transformer(src_data, x_mask, tgt_data[:, :-1])\n                loss = criterion(output.contiguous().view(-1, settings[\"tgt_vocab_size\"]), \n                                 tgt_data[:, 1:].contiguous().view(-1).long())\n\n                if is_train:\n                    loss.backward()\n                    optimizer.step()\n\n            epoch_loss += loss.item()\n\n            # Calculate masked accuracy\n            output_tokens = output.argmax(dim=-1)  # Shape: (batch_size, seq_len)\n            non_pad_mask = tgt_data[:, 1:] != settings[\"padding_token\"]  # Ignore padding tokens (mask for target data)\n            correct = (output_tokens == tgt_data[:, 1:]) & non_pad_mask  # Compare predictions to targets and ignore padding\n            total_correct += correct.sum().item()\n            total_tokens += non_pad_mask.sum().item()\n\n            # Calculate masked Levenshtein distance\n            total_levenshtein_distance += masked_levenshtein(output_tokens, tgt_data[:, 1:])\n\n        avg_loss = epoch_loss / len(loader)\n        accuracy = total_correct / total_tokens\n        return avg_loss, accuracy, total_levenshtein_distance/(settings[\"batch_size\"]*len(loader))\n\n    training_metrics = []\n    for epoch in range(settings[\"epochs\"]):\n        train_loss, train_accuracy, train_levenshtein = run_epoch(train_loader, is_train=True)\n        valid_loss, valid_accuracy, valid_levenshtein = run_epoch(valid_loader, is_train=False)\n\n        display_text = f\"Epoch {epoch+1}\"\n        display_text += f\" | Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Train Levenshtein: {train_levenshtein:.4f}\"\n        display_text += f\" | Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}, Valid Levenshtein: {valid_levenshtein:.4f}\"\n        print(display_text)\n\n        training_metrics.append([epoch+1, train_loss, train_accuracy, train_levenshtein, valid_loss, valid_accuracy, valid_levenshtein])\n        \n    # Eval on test dataset\n    test_loss, test_accuracy, test_levenshtein = run_epoch(test_loader, is_train=False)\n    width = 34\n    print(\"\\n\" + \"=\" * width)\n    print(\" Evaluation Results \")\n    print(\"=\" * width)\n    print(f\" Test Loss: {test_loss:.4f}\")\n    print(f\" Test Accuracy: {100*test_accuracy:.2f}%\")\n    print(f\" Test Levenshtein Distance: {test_levenshtein:.2f}\")\n    print(\"=\" * width)\n    \n    # Save results\n    \n    output_folder = settings['config_name']\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n    \n    ## Save settings\n    settings_path = os.path.join(output_folder, \"settings.json\")\n    with open(settings_path, \"w\") as settings_file:\n        settings_file.write(json.dumps(settings, indent=4))\n\n    ## Save test results\n    test_results_path = os.path.join(output_folder, \"test_results.json\")\n    with open(test_results_path, \"w\") as test_results_file:\n        test_results_file.write(json.dumps({\n            \"loss\": test_loss,\n            \"accuracy\": test_accuracy,\n            \"edit_dist\": test_levenshtein\n        }))\n\n    ## Save model\n    model_path = os.path.join(output_folder, 'model.pth')\n    torch.save(transformer.state_dict(), model_path)\n\n    ## Save training metrics\n    training_metrics_path = os.path.join(output_folder, \"training_metrics.csv\")\n    training_metrics_df = pd.DataFrame(\n        training_metrics,\n        columns=['epoch', 'train_loss', 'train_accuracy', 'train_levenshtein', 'valid_loss', 'valid_accuracy', 'valid_levenshtein']\n    )\n    training_metrics_df.to_csv(training_metrics_path, index=False)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:54:29.929958Z","iopub.execute_input":"2024-10-20T20:54:29.930345Z","iopub.status.idle":"2024-10-20T20:54:29.955090Z","shell.execute_reply.started":"2024-10-20T20:54:29.930310Z","shell.execute_reply":"2024-10-20T20:54:29.954198Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import uuid\nimport copy\n\nsetting_variations = []\nfor MODEL_NAME, MODEL_SIZE in zip([\"small\", \"medium\", \"large\"], [64, 128, 256]):\n    global_settings = {\n        # Data\n        \"d_model\": MODEL_SIZE,\n        \"seq_len\": SEQ_LEN,\n        \"padding_token\": token_map[PADDING],\n\n        # Training\n        \"batch_size\": BATCH_SIZE,\n        \"epochs\": 30,\n\n        # Transformer\n        \"num_nodes_per_hand\": 21,\n        \"num_features_per_node\": 3,\n        \"tgt_vocab_size\": len(token_map),\n        \"num_heads\": 2,\n        \"num_enc_layer\": 2,\n        \"num_dec_layer\": 4,\n        \"dff\": MODEL_SIZE,\n        \"dropout\": 0.1,\n        \"phrase_length\": max_phrase_len_with_sequence_control_tokens,\n    }\n\n    embedding_settings = [\n        {\n            \"embedding\": {\n                \"name\": \"graph_embedding\",\n                \"layer_type\": \"gcn_conv\",\n                \"num_layers\": 2,\n                \"attention_heads\": 2,\n                \"hidden_dim\": MODEL_SIZE,\n            }\n        },\n        {\n            \"embedding\": {\n                \"name\": \"graph_embedding\",\n                \"layer_type\": \"gat_conv\",\n                \"num_layers\": 2,\n                \"attention_heads\": 2,\n                \"hidden_dim\": MODEL_SIZE,\n            }\n        },\n        {\n            \"embedding\": {\n                \"name\": \"graph_embedding\",\n                \"layer_type\": \"gat_conv_v2\",\n                \"num_layers\": 2,\n                \"attention_heads\": 2,\n                \"hidden_dim\": MODEL_SIZE,\n            }\n        },\n        {\n            \"embedding\": {\n                \"name\": \"landmark_embedding\",\n                \"num_conv_layers\": 3,\n                \"filter_size\": 11,\n            }\n        }\n    ]\n    \n    for embed_setting in embedding_settings:\n        global_settings.update(embed_setting)\n        embed_name = \"landmark_embedding\" if global_settings[\"embedding\"][\"name\"] == \"landmark_embedding\" else global_settings[\"embedding\"][\"layer_type\"]\n        global_settings[\"config_name\"] = f\"{MODEL_NAME}-{embed_name}\"\n        setting_variations.append(copy.deepcopy(global_settings))","metadata":{"execution":{"iopub.status.busy":"2024-10-20T21:09:24.221603Z","iopub.execute_input":"2024-10-20T21:09:24.222262Z","iopub.status.idle":"2024-10-20T21:09:24.230931Z","shell.execute_reply.started":"2024-10-20T21:09:24.222210Z","shell.execute_reply":"2024-10-20T21:09:24.230037Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"[f'{it[\"config_name\"]} - {it[\"epochs\"]}' for it in setting_variations]","metadata":{"execution":{"iopub.status.busy":"2024-10-20T21:10:41.289366Z","iopub.execute_input":"2024-10-20T21:10:41.290488Z","iopub.status.idle":"2024-10-20T21:10:41.300954Z","shell.execute_reply.started":"2024-10-20T21:10:41.290431Z","shell.execute_reply":"2024-10-20T21:10:41.299937Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"['small-gat_conv - 100', 'small-landmark_embedding - 100']"},"metadata":{}}]},{"cell_type":"code","source":"for setting in setting_variations:\n    print(f\"Running {setting['config_name']}\")\n    print()\n    eval_settings(setting)\n    print()\n    print(\"#\"*40)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-10-20T21:10:46.450997Z","iopub.execute_input":"2024-10-20T21:10:46.451661Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Running small-gat_conv\n\nEpoch 1 | Train Loss: 2.6197, Train Accuracy: 0.2239, Train Levenshtein: 13.6342 | Valid Loss: 2.3871, Valid Accuracy: 0.2733, Valid Levenshtein: 12.1061\nEpoch 2 | Train Loss: 2.3752, Train Accuracy: 0.2773, Train Levenshtein: 12.1667 | Valid Loss: 2.2829, Valid Accuracy: 0.2997, Valid Levenshtein: 12.1497\nEpoch 3 | Train Loss: 2.2955, Train Accuracy: 0.2966, Train Levenshtein: 11.7466 | Valid Loss: 2.2235, Valid Accuracy: 0.3214, Valid Levenshtein: 11.3474\nEpoch 4 | Train Loss: 2.2447, Train Accuracy: 0.3114, Train Levenshtein: 11.4119 | Valid Loss: 2.1766, Valid Accuracy: 0.3301, Valid Levenshtein: 11.1526\nEpoch 5 | Train Loss: 2.2057, Train Accuracy: 0.3208, Train Levenshtein: 11.1543 | Valid Loss: 2.1421, Valid Accuracy: 0.3420, Valid Levenshtein: 10.8910\nEpoch 6 | Train Loss: 2.1758, Train Accuracy: 0.3295, Train Levenshtein: 11.0164 | Valid Loss: 2.1177, Valid Accuracy: 0.3488, Valid Levenshtein: 10.8924\nEpoch 7 | Train Loss: 2.1475, Train Accuracy: 0.3373, Train Levenshtein: 10.9098 | Valid Loss: 2.0892, Valid Accuracy: 0.3544, Valid Levenshtein: 10.7674\nEpoch 8 | Train Loss: 2.1189, Train Accuracy: 0.3441, Train Levenshtein: 10.8367 | Valid Loss: 2.0614, Valid Accuracy: 0.3597, Valid Levenshtein: 10.7057\nEpoch 9 | Train Loss: 2.0800, Train Accuracy: 0.3559, Train Levenshtein: 10.6306 | Valid Loss: 2.0215, Valid Accuracy: 0.3756, Valid Levenshtein: 10.4629\nEpoch 10 | Train Loss: 2.0516, Train Accuracy: 0.3618, Train Levenshtein: 10.5148 | Valid Loss: 1.9941, Valid Accuracy: 0.3812, Valid Levenshtein: 10.3045\nEpoch 11 | Train Loss: 2.0211, Train Accuracy: 0.3722, Train Levenshtein: 10.3494 | Valid Loss: 1.9698, Valid Accuracy: 0.3877, Valid Levenshtein: 10.2115\nEpoch 12 | Train Loss: 1.9979, Train Accuracy: 0.3781, Train Levenshtein: 10.2539 | Valid Loss: 1.9459, Valid Accuracy: 0.3979, Valid Levenshtein: 10.0516\nEpoch 13 | Train Loss: 1.9747, Train Accuracy: 0.3862, Train Levenshtein: 10.1302 | Valid Loss: 1.9540, Valid Accuracy: 0.3942, Valid Levenshtein: 10.0916\nEpoch 14 | Train Loss: 1.9539, Train Accuracy: 0.3931, Train Levenshtein: 10.0081 | Valid Loss: 1.9117, Valid Accuracy: 0.4082, Valid Levenshtein: 9.8270\nEpoch 15 | Train Loss: 1.9337, Train Accuracy: 0.3985, Train Levenshtein: 9.9269 | Valid Loss: 1.8862, Valid Accuracy: 0.4162, Valid Levenshtein: 9.7914\nEpoch 16 | Train Loss: 1.9119, Train Accuracy: 0.4056, Train Levenshtein: 9.8267 | Valid Loss: 1.8732, Valid Accuracy: 0.4198, Valid Levenshtein: 9.6715\nEpoch 17 | Train Loss: 1.8878, Train Accuracy: 0.4133, Train Levenshtein: 9.7031 | Valid Loss: 1.8772, Valid Accuracy: 0.4222, Valid Levenshtein: 9.6119\nEpoch 18 | Train Loss: 1.8653, Train Accuracy: 0.4192, Train Levenshtein: 9.6002 | Valid Loss: 1.8266, Valid Accuracy: 0.4332, Valid Levenshtein: 9.4375\nEpoch 19 | Train Loss: 1.8426, Train Accuracy: 0.4253, Train Levenshtein: 9.4982 | Valid Loss: 1.8060, Valid Accuracy: 0.4361, Valid Levenshtein: 9.4026\nEpoch 20 | Train Loss: 1.8241, Train Accuracy: 0.4324, Train Levenshtein: 9.3969 | Valid Loss: 1.8248, Valid Accuracy: 0.4362, Valid Levenshtein: 9.5509\nEpoch 21 | Train Loss: 1.8045, Train Accuracy: 0.4371, Train Levenshtein: 9.3434 | Valid Loss: 1.7796, Valid Accuracy: 0.4467, Valid Levenshtein: 9.2464\nEpoch 22 | Train Loss: 1.7890, Train Accuracy: 0.4434, Train Levenshtein: 9.2416 | Valid Loss: 1.7684, Valid Accuracy: 0.4506, Valid Levenshtein: 9.1795\nEpoch 23 | Train Loss: 1.7699, Train Accuracy: 0.4493, Train Levenshtein: 9.1431 | Valid Loss: 1.7572, Valid Accuracy: 0.4572, Valid Levenshtein: 9.0756\nEpoch 24 | Train Loss: 1.7510, Train Accuracy: 0.4539, Train Levenshtein: 9.0735 | Valid Loss: 1.7281, Valid Accuracy: 0.4700, Valid Levenshtein: 8.9019\nEpoch 25 | Train Loss: 1.7269, Train Accuracy: 0.4627, Train Levenshtein: 8.9344 | Valid Loss: 1.6978, Valid Accuracy: 0.4778, Valid Levenshtein: 8.7260\nEpoch 26 | Train Loss: 1.6979, Train Accuracy: 0.4726, Train Levenshtein: 8.7748 | Valid Loss: 1.6642, Valid Accuracy: 0.4889, Valid Levenshtein: 8.5603\nEpoch 27 | Train Loss: 1.6661, Train Accuracy: 0.4836, Train Levenshtein: 8.6084 | Valid Loss: 1.6226, Valid Accuracy: 0.5041, Valid Levenshtein: 8.4281\nEpoch 28 | Train Loss: 1.6345, Train Accuracy: 0.4955, Train Levenshtein: 8.4096 | Valid Loss: 1.5904, Valid Accuracy: 0.5164, Valid Levenshtein: 8.2180\nEpoch 29 | Train Loss: 1.6047, Train Accuracy: 0.5061, Train Levenshtein: 8.2209 | Valid Loss: 1.5601, Valid Accuracy: 0.5275, Valid Levenshtein: 7.9266\nEpoch 30 | Train Loss: 1.5803, Train Accuracy: 0.5145, Train Levenshtein: 8.0846 | Valid Loss: 1.5347, Valid Accuracy: 0.5376, Valid Levenshtein: 7.7660\nEpoch 31 | Train Loss: 1.5537, Train Accuracy: 0.5231, Train Levenshtein: 7.9298 | Valid Loss: 1.5236, Valid Accuracy: 0.5426, Valid Levenshtein: 7.7311\nEpoch 32 | Train Loss: 1.5288, Train Accuracy: 0.5329, Train Levenshtein: 7.8094 | Valid Loss: 1.4976, Valid Accuracy: 0.5518, Valid Levenshtein: 7.7013\nEpoch 33 | Train Loss: 1.5048, Train Accuracy: 0.5418, Train Levenshtein: 7.6641 | Valid Loss: 1.4665, Valid Accuracy: 0.5631, Valid Levenshtein: 7.5865\nEpoch 34 | Train Loss: 1.4854, Train Accuracy: 0.5476, Train Levenshtein: 7.5925 | Valid Loss: 1.4598, Valid Accuracy: 0.5663, Valid Levenshtein: 7.4259\nEpoch 35 | Train Loss: 1.4650, Train Accuracy: 0.5547, Train Levenshtein: 7.4603 | Valid Loss: 1.4182, Valid Accuracy: 0.5775, Valid Levenshtein: 7.4724\nEpoch 36 | Train Loss: 1.4408, Train Accuracy: 0.5637, Train Levenshtein: 7.3582 | Valid Loss: 1.4099, Valid Accuracy: 0.5816, Valid Levenshtein: 7.4179\nEpoch 37 | Train Loss: 1.4259, Train Accuracy: 0.5681, Train Levenshtein: 7.2575 | Valid Loss: 1.4107, Valid Accuracy: 0.5841, Valid Levenshtein: 7.2144\nEpoch 38 | Train Loss: 1.4058, Train Accuracy: 0.5761, Train Levenshtein: 7.1421 | Valid Loss: 1.3901, Valid Accuracy: 0.5876, Valid Levenshtein: 7.0901\nEpoch 39 | Train Loss: 1.3852, Train Accuracy: 0.5825, Train Levenshtein: 7.0581 | Valid Loss: 1.3543, Valid Accuracy: 0.6000, Valid Levenshtein: 7.0988\nEpoch 40 | Train Loss: 1.3685, Train Accuracy: 0.5880, Train Levenshtein: 6.9293 | Valid Loss: 1.3337, Valid Accuracy: 0.6084, Valid Levenshtein: 6.6344\nEpoch 41 | Train Loss: 1.3483, Train Accuracy: 0.5940, Train Levenshtein: 6.8493 | Valid Loss: 1.3130, Valid Accuracy: 0.6124, Valid Levenshtein: 6.5923\nEpoch 42 | Train Loss: 1.3363, Train Accuracy: 0.5964, Train Levenshtein: 6.7692 | Valid Loss: 1.3179, Valid Accuracy: 0.6158, Valid Levenshtein: 6.5291\nEpoch 43 | Train Loss: 1.3157, Train Accuracy: 0.6049, Train Levenshtein: 6.6199 | Valid Loss: 1.2871, Valid Accuracy: 0.6217, Valid Levenshtein: 6.4157\nEpoch 44 | Train Loss: 1.3018, Train Accuracy: 0.6090, Train Levenshtein: 6.5537 | Valid Loss: 1.2763, Valid Accuracy: 0.6252, Valid Levenshtein: 6.3881\nEpoch 45 | Train Loss: 1.2862, Train Accuracy: 0.6131, Train Levenshtein: 6.4558 | Valid Loss: 1.2614, Valid Accuracy: 0.6333, Valid Levenshtein: 6.1359\nEpoch 46 | Train Loss: 1.2731, Train Accuracy: 0.6180, Train Levenshtein: 6.4239 | Valid Loss: 1.2569, Valid Accuracy: 0.6341, Valid Levenshtein: 6.2195\nEpoch 47 | Train Loss: 1.2549, Train Accuracy: 0.6245, Train Levenshtein: 6.2758 | Valid Loss: 1.2477, Valid Accuracy: 0.6374, Valid Levenshtein: 6.2413\nEpoch 48 | Train Loss: 1.2478, Train Accuracy: 0.6266, Train Levenshtein: 6.2397 | Valid Loss: 1.2283, Valid Accuracy: 0.6453, Valid Levenshtein: 6.0458\nEpoch 49 | Train Loss: 1.2321, Train Accuracy: 0.6299, Train Levenshtein: 6.2021 | Valid Loss: 1.2236, Valid Accuracy: 0.6398, Valid Levenshtein: 6.1374\nEpoch 50 | Train Loss: 1.2211, Train Accuracy: 0.6337, Train Levenshtein: 6.1160 | Valid Loss: 1.2170, Valid Accuracy: 0.6465, Valid Levenshtein: 5.9935\nEpoch 51 | Train Loss: 1.2113, Train Accuracy: 0.6368, Train Levenshtein: 6.0844 | Valid Loss: 1.2011, Valid Accuracy: 0.6513, Valid Levenshtein: 5.9448\nEpoch 52 | Train Loss: 1.1999, Train Accuracy: 0.6399, Train Levenshtein: 6.0495 | Valid Loss: 1.1842, Valid Accuracy: 0.6548, Valid Levenshtein: 5.8474\nEpoch 53 | Train Loss: 1.1939, Train Accuracy: 0.6414, Train Levenshtein: 6.0133 | Valid Loss: 1.1924, Valid Accuracy: 0.6528, Valid Levenshtein: 5.9738\nEpoch 54 | Train Loss: 1.1817, Train Accuracy: 0.6462, Train Levenshtein: 5.9339 | Valid Loss: 1.1774, Valid Accuracy: 0.6580, Valid Levenshtein: 5.8169\nEpoch 55 | Train Loss: 1.1721, Train Accuracy: 0.6491, Train Levenshtein: 5.9226 | Valid Loss: 1.1796, Valid Accuracy: 0.6596, Valid Levenshtein: 5.8358\nEpoch 56 | Train Loss: 1.1600, Train Accuracy: 0.6528, Train Levenshtein: 5.8465 | Valid Loss: 1.1571, Valid Accuracy: 0.6643, Valid Levenshtein: 5.7064\nEpoch 57 | Train Loss: 1.1524, Train Accuracy: 0.6547, Train Levenshtein: 5.8041 | Valid Loss: 1.1663, Valid Accuracy: 0.6626, Valid Levenshtein: 5.7078\nEpoch 58 | Train Loss: 1.1462, Train Accuracy: 0.6565, Train Levenshtein: 5.8087 | Valid Loss: 1.1516, Valid Accuracy: 0.6658, Valid Levenshtein: 6.2311\nEpoch 59 | Train Loss: 1.1362, Train Accuracy: 0.6597, Train Levenshtein: 5.7871 | Valid Loss: 1.1444, Valid Accuracy: 0.6704, Valid Levenshtein: 5.6948\nEpoch 60 | Train Loss: 1.1281, Train Accuracy: 0.6612, Train Levenshtein: 5.7381 | Valid Loss: 1.1338, Valid Accuracy: 0.6753, Valid Levenshtein: 5.5828\nEpoch 61 | Train Loss: 1.1220, Train Accuracy: 0.6642, Train Levenshtein: 5.7112 | Valid Loss: 1.1172, Valid Accuracy: 0.6796, Valid Levenshtein: 5.4375\nEpoch 62 | Train Loss: 1.1167, Train Accuracy: 0.6664, Train Levenshtein: 5.6215 | Valid Loss: 1.1309, Valid Accuracy: 0.6748, Valid Levenshtein: 5.7333\nEpoch 63 | Train Loss: 1.1064, Train Accuracy: 0.6700, Train Levenshtein: 5.5467 | Valid Loss: 1.1287, Valid Accuracy: 0.6732, Valid Levenshtein: 5.5371\nEpoch 64 | Train Loss: 1.1061, Train Accuracy: 0.6674, Train Levenshtein: 5.6041 | Valid Loss: 1.1044, Valid Accuracy: 0.6794, Valid Levenshtein: 5.3975\nEpoch 65 | Train Loss: 1.0982, Train Accuracy: 0.6709, Train Levenshtein: 5.5338 | Valid Loss: 1.1301, Valid Accuracy: 0.6784, Valid Levenshtein: 5.4164\nEpoch 66 | Train Loss: 1.0888, Train Accuracy: 0.6749, Train Levenshtein: 5.4850 | Valid Loss: 1.1118, Valid Accuracy: 0.6784, Valid Levenshtein: 5.6148\nEpoch 67 | Train Loss: 1.0813, Train Accuracy: 0.6769, Train Levenshtein: 5.4445 | Valid Loss: 1.1107, Valid Accuracy: 0.6810, Valid Levenshtein: 5.4172\nEpoch 68 | Train Loss: 1.0780, Train Accuracy: 0.6773, Train Levenshtein: 5.4657 | Valid Loss: 1.1130, Valid Accuracy: 0.6830, Valid Levenshtein: 5.3677\nEpoch 69 | Train Loss: 1.0731, Train Accuracy: 0.6792, Train Levenshtein: 5.4641 | Valid Loss: 1.1220, Valid Accuracy: 0.6787, Valid Levenshtein: 5.5174\nEpoch 70 | Train Loss: 1.0662, Train Accuracy: 0.6797, Train Levenshtein: 5.4951 | Valid Loss: 1.0767, Valid Accuracy: 0.6909, Valid Levenshtein: 5.3081\nEpoch 71 | Train Loss: 1.0615, Train Accuracy: 0.6823, Train Levenshtein: 5.4662 | Valid Loss: 1.0876, Valid Accuracy: 0.6861, Valid Levenshtein: 5.5262\nEpoch 72 | Train Loss: 1.0578, Train Accuracy: 0.6831, Train Levenshtein: 5.4488 | Valid Loss: 1.0770, Valid Accuracy: 0.6923, Valid Levenshtein: 5.4310\nEpoch 73 | Train Loss: 1.0468, Train Accuracy: 0.6872, Train Levenshtein: 5.3913 | Valid Loss: 1.0854, Valid Accuracy: 0.6908, Valid Levenshtein: 5.2863\nEpoch 74 | Train Loss: 1.0426, Train Accuracy: 0.6880, Train Levenshtein: 5.3723 | Valid Loss: 1.0901, Valid Accuracy: 0.6863, Valid Levenshtein: 5.3372\nEpoch 75 | Train Loss: 1.0410, Train Accuracy: 0.6894, Train Levenshtein: 5.3415 | Valid Loss: 1.0703, Valid Accuracy: 0.6944, Valid Levenshtein: 5.3481\nEpoch 76 | Train Loss: 1.0331, Train Accuracy: 0.6911, Train Levenshtein: 5.3319 | Valid Loss: 1.0850, Valid Accuracy: 0.6863, Valid Levenshtein: 5.5000\nEpoch 77 | Train Loss: 1.0287, Train Accuracy: 0.6930, Train Levenshtein: 5.2501 | Valid Loss: 1.0610, Valid Accuracy: 0.6969, Valid Levenshtein: 5.2783\nEpoch 78 | Train Loss: 1.0250, Train Accuracy: 0.6938, Train Levenshtein: 5.2644 | Valid Loss: 1.0648, Valid Accuracy: 0.6944, Valid Levenshtein: 5.2188\nEpoch 79 | Train Loss: 1.0169, Train Accuracy: 0.6952, Train Levenshtein: 5.1864 | Valid Loss: 1.0676, Valid Accuracy: 0.6945, Valid Levenshtein: 5.5640\nEpoch 80 | Train Loss: 1.0176, Train Accuracy: 0.6959, Train Levenshtein: 5.1848 | Valid Loss: 1.0591, Valid Accuracy: 0.6959, Valid Levenshtein: 5.2318\nEpoch 81 | Train Loss: 1.0098, Train Accuracy: 0.6979, Train Levenshtein: 5.1443 | Valid Loss: 1.0542, Valid Accuracy: 0.7020, Valid Levenshtein: 5.0494\nEpoch 82 | Train Loss: 1.0043, Train Accuracy: 0.6986, Train Levenshtein: 5.1206 | Valid Loss: 1.0451, Valid Accuracy: 0.7008, Valid Levenshtein: 5.1650\nEpoch 83 | Train Loss: 0.9997, Train Accuracy: 0.7005, Train Levenshtein: 5.0729 | Valid Loss: 1.0284, Valid Accuracy: 0.7034, Valid Levenshtein: 5.0334\nEpoch 84 | Train Loss: 0.9963, Train Accuracy: 0.7014, Train Levenshtein: 5.1023 | Valid Loss: 1.0359, Valid Accuracy: 0.7039, Valid Levenshtein: 5.1301\nEpoch 85 | Train Loss: 0.9934, Train Accuracy: 0.7029, Train Levenshtein: 5.0819 | Valid Loss: 1.0323, Valid Accuracy: 0.7071, Valid Levenshtein: 5.0451\nEpoch 86 | Train Loss: 0.9868, Train Accuracy: 0.7051, Train Levenshtein: 5.0452 | Valid Loss: 1.0249, Valid Accuracy: 0.7048, Valid Levenshtein: 5.0741\nEpoch 87 | Train Loss: 0.9827, Train Accuracy: 0.7054, Train Levenshtein: 5.0254 | Valid Loss: 1.0608, Valid Accuracy: 0.6973, Valid Levenshtein: 5.2449\nEpoch 88 | Train Loss: 0.9778, Train Accuracy: 0.7078, Train Levenshtein: 4.9887 | Valid Loss: 1.0273, Valid Accuracy: 0.7030, Valid Levenshtein: 5.1468\nEpoch 89 | Train Loss: 0.9756, Train Accuracy: 0.7082, Train Levenshtein: 4.9969 | Valid Loss: 1.0447, Valid Accuracy: 0.7040, Valid Levenshtein: 5.0756\nEpoch 90 | Train Loss: 0.9751, Train Accuracy: 0.7082, Train Levenshtein: 5.0105 | Valid Loss: 1.0386, Valid Accuracy: 0.7032, Valid Levenshtein: 5.1635\nEpoch 91 | Train Loss: 0.9704, Train Accuracy: 0.7090, Train Levenshtein: 5.0330 | Valid Loss: 1.0299, Valid Accuracy: 0.7064, Valid Levenshtein: 5.1475\nEpoch 92 | Train Loss: 0.9675, Train Accuracy: 0.7103, Train Levenshtein: 5.0065 | Valid Loss: 1.0226, Valid Accuracy: 0.7104, Valid Levenshtein: 5.0131\nEpoch 93 | Train Loss: 0.9588, Train Accuracy: 0.7123, Train Levenshtein: 4.9299 | Valid Loss: 1.0219, Valid Accuracy: 0.7108, Valid Levenshtein: 4.9281\nEpoch 94 | Train Loss: 0.9599, Train Accuracy: 0.7126, Train Levenshtein: 4.9202 | Valid Loss: 1.0318, Valid Accuracy: 0.7042, Valid Levenshtein: 5.1148\nEpoch 95 | Train Loss: 0.9536, Train Accuracy: 0.7145, Train Levenshtein: 4.8515 | Valid Loss: 1.0170, Valid Accuracy: 0.7102, Valid Levenshtein: 4.9586\nEpoch 96 | Train Loss: 0.9482, Train Accuracy: 0.7153, Train Levenshtein: 4.8814 | Valid Loss: 1.0076, Valid Accuracy: 0.7136, Valid Levenshtein: 5.0247\nEpoch 97 | Train Loss: 0.9457, Train Accuracy: 0.7170, Train Levenshtein: 4.8453 | Valid Loss: 1.0258, Valid Accuracy: 0.7087, Valid Levenshtein: 5.2217\nEpoch 98 | Train Loss: 0.9427, Train Accuracy: 0.7172, Train Levenshtein: 4.8066 | Valid Loss: 1.0180, Valid Accuracy: 0.7132, Valid Levenshtein: 4.9491\nEpoch 99 | Train Loss: 0.9431, Train Accuracy: 0.7177, Train Levenshtein: 4.8483 | Valid Loss: 1.0240, Valid Accuracy: 0.7077, Valid Levenshtein: 5.0669\nEpoch 100 | Train Loss: 0.9392, Train Accuracy: 0.7190, Train Levenshtein: 4.7653 | Valid Loss: 1.0115, Valid Accuracy: 0.7147, Valid Levenshtein: 4.8794\n\n==================================\n Evaluation Results \n==================================\n Test Loss: 0.9838\n Test Accuracy: 71.47%\n Test Levenshtein Distance: 4.90\n==================================\n\n########################################\n\nRunning small-landmark_embedding\n\nEpoch 1 | Train Loss: 2.6406, Train Accuracy: 0.2194, Train Levenshtein: 16.5684 | Valid Loss: 2.4150, Valid Accuracy: 0.2664, Valid Levenshtein: 15.6294\nEpoch 2 | Train Loss: 2.3962, Train Accuracy: 0.2693, Train Levenshtein: 15.6979 | Valid Loss: 2.3028, Valid Accuracy: 0.2943, Valid Levenshtein: 15.3241\nEpoch 3 | Train Loss: 2.3198, Train Accuracy: 0.2909, Train Levenshtein: 14.7970 | Valid Loss: 2.2363, Valid Accuracy: 0.3113, Valid Levenshtein: 15.8568\nEpoch 4 | Train Loss: 2.2709, Train Accuracy: 0.3018, Train Levenshtein: 14.0847 | Valid Loss: 2.2007, Valid Accuracy: 0.3222, Valid Levenshtein: 13.4295\nEpoch 5 | Train Loss: 2.2342, Train Accuracy: 0.3118, Train Levenshtein: 12.8466 | Valid Loss: 2.1690, Valid Accuracy: 0.3317, Valid Levenshtein: 13.3343\nEpoch 6 | Train Loss: 2.2036, Train Accuracy: 0.3187, Train Levenshtein: 11.8933 | Valid Loss: 2.1399, Valid Accuracy: 0.3368, Valid Levenshtein: 12.0225\nEpoch 7 | Train Loss: 2.1820, Train Accuracy: 0.3253, Train Levenshtein: 11.4404 | Valid Loss: 2.1182, Valid Accuracy: 0.3416, Valid Levenshtein: 11.8837\nEpoch 8 | Train Loss: 2.1626, Train Accuracy: 0.3310, Train Levenshtein: 11.3318 | Valid Loss: 2.1003, Valid Accuracy: 0.3497, Valid Levenshtein: 11.1526\nEpoch 9 | Train Loss: 2.1464, Train Accuracy: 0.3358, Train Levenshtein: 11.2014 | Valid Loss: 2.0897, Valid Accuracy: 0.3556, Valid Levenshtein: 11.1163\nEpoch 10 | Train Loss: 2.1313, Train Accuracy: 0.3400, Train Levenshtein: 11.1206 | Valid Loss: 2.0834, Valid Accuracy: 0.3563, Valid Levenshtein: 11.2166\nEpoch 11 | Train Loss: 2.1170, Train Accuracy: 0.3426, Train Levenshtein: 11.1316 | Valid Loss: 2.0603, Valid Accuracy: 0.3598, Valid Levenshtein: 10.8459\nEpoch 12 | Train Loss: 2.1054, Train Accuracy: 0.3452, Train Levenshtein: 10.9887 | Valid Loss: 2.0522, Valid Accuracy: 0.3679, Valid Levenshtein: 10.9440\nEpoch 13 | Train Loss: 2.0939, Train Accuracy: 0.3501, Train Levenshtein: 10.9485 | Valid Loss: 2.0468, Valid Accuracy: 0.3652, Valid Levenshtein: 11.2166\nEpoch 14 | Train Loss: 2.0854, Train Accuracy: 0.3520, Train Levenshtein: 10.9160 | Valid Loss: 2.0372, Valid Accuracy: 0.3650, Valid Levenshtein: 11.0516\nEpoch 15 | Train Loss: 2.0788, Train Accuracy: 0.3532, Train Levenshtein: 10.8683 | Valid Loss: 2.0301, Valid Accuracy: 0.3723, Valid Levenshtein: 10.6286\nEpoch 16 | Train Loss: 2.0679, Train Accuracy: 0.3567, Train Levenshtein: 10.8103 | Valid Loss: 2.0308, Valid Accuracy: 0.3700, Valid Levenshtein: 10.9033\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport zipfile\n\ndef zip_all_folders_in_directory(directory_path, output_zip_name):\n    # Create a ZipFile object for the single output zip\n    zip_file_path = os.path.join(directory_path, output_zip_name)\n    with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n        # Loop over all items in the directory\n        for folder_name in os.listdir(directory_path):\n            folder_path = os.path.join(directory_path, folder_name)\n            # Check if the item is a directory\n            if os.path.isdir(folder_path):\n                # Walk through the folder and add its contents to the zip file\n                for root, _, files in os.walk(folder_path):\n                    for file in files:\n                        file_path = os.path.join(root, file)\n                        # Add the file to the zip file, maintaining the folder structure\n                        arcname = os.path.relpath(file_path, directory_path)\n                        zip_file.write(file_path, arcname)\n\n    print(f\"All folders have been zipped into {output_zip_name} successfully.\")\n    \ndef remove_non_zip_files(folder_path):\n    # Walk through all directories and files in the specified folder\n    for dirpath, dirnames, filenames in os.walk(folder_path, topdown=False):\n        # Remove non-zip files in the current directory\n        for file in filenames:\n            if not file.endswith('.zip'):\n                os.remove(os.path.join(dirpath, file))  # Remove the file\n\n        for dirname in dirnames:\n            dir_to_remove = os.path.join(dirpath, dirname)\n            if not os.listdir(dir_to_remove):  # Only remove if empty\n                os.rmdir(dir_to_remove)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T21:03:02.429583Z","iopub.execute_input":"2024-10-20T21:03:02.430302Z","iopub.status.idle":"2024-10-20T21:03:02.439649Z","shell.execute_reply.started":"2024-10-20T21:03:02.430264Z","shell.execute_reply":"2024-10-20T21:03:02.438775Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"zip_all_folders_in_directory(\"/kaggle/working/\", f\"research_result-{str(uuid.uuid4())}.zip\")","metadata":{"execution":{"iopub.status.busy":"2024-10-20T21:03:18.113413Z","iopub.execute_input":"2024-10-20T21:03:18.113775Z","iopub.status.idle":"2024-10-20T21:03:23.883167Z","shell.execute_reply.started":"2024-10-20T21:03:18.113743Z","shell.execute_reply":"2024-10-20T21:03:23.882225Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"All folders have been zipped into research_result-d995e18a-2232-4089-a3bd-4d965a65ff2e.zip successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"remove_non_zip_files(\"/kaggle/working/\")","metadata":{"execution":{"iopub.status.busy":"2024-10-20T21:06:01.971674Z","iopub.execute_input":"2024-10-20T21:06:01.972046Z","iopub.status.idle":"2024-10-20T21:06:01.989644Z","shell.execute_reply.started":"2024-10-20T21:06:01.972010Z","shell.execute_reply":"2024-10-20T21:06:01.988897Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}