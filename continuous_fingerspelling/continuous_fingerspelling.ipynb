{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Transformer Architecture\n",
    "\n",
    "Sources:\n",
    "\n",
    "- [correct `transformer implementation` from scratch in `pytorch`](https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb) (in-depth tutorial from same author: [part1](https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021), [part2](https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-2-bf2403804ada))\n",
    "- [nice visuals for understanding `multi-head attention`](http://jalammar.github.io/illustrated-transformer/)\n",
    "- [`positional encoding`](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)\n",
    "- [kaggle transformer code: ❗Contains mistakes (see comments), but nice overall explanation](https://www.kaggle.com/code/arunmohan003/transformer-from-scratch-using-pytorch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.4.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "print(f\"torch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "For details about the dataset see `data_handling.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_dominant_hand_0</th>\n",
       "      <th>x_dominant_hand_1</th>\n",
       "      <th>x_dominant_hand_2</th>\n",
       "      <th>x_dominant_hand_3</th>\n",
       "      <th>x_dominant_hand_4</th>\n",
       "      <th>x_dominant_hand_5</th>\n",
       "      <th>x_dominant_hand_6</th>\n",
       "      <th>x_dominant_hand_7</th>\n",
       "      <th>x_dominant_hand_8</th>\n",
       "      <th>x_dominant_hand_9</th>\n",
       "      <th>...</th>\n",
       "      <th>z_dominant_hand_11</th>\n",
       "      <th>z_dominant_hand_12</th>\n",
       "      <th>z_dominant_hand_13</th>\n",
       "      <th>z_dominant_hand_14</th>\n",
       "      <th>z_dominant_hand_15</th>\n",
       "      <th>z_dominant_hand_16</th>\n",
       "      <th>z_dominant_hand_17</th>\n",
       "      <th>z_dominant_hand_18</th>\n",
       "      <th>z_dominant_hand_19</th>\n",
       "      <th>z_dominant_hand_20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>0.408832</td>\n",
       "      <td>0.519912</td>\n",
       "      <td>0.612159</td>\n",
       "      <td>0.707576</td>\n",
       "      <td>0.797313</td>\n",
       "      <td>0.494709</td>\n",
       "      <td>0.532817</td>\n",
       "      <td>0.553556</td>\n",
       "      <td>0.566219</td>\n",
       "      <td>0.391196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245855</td>\n",
       "      <td>-0.269148</td>\n",
       "      <td>-0.129743</td>\n",
       "      <td>-0.251501</td>\n",
       "      <td>-0.278687</td>\n",
       "      <td>-0.266530</td>\n",
       "      <td>-0.152852</td>\n",
       "      <td>-0.257519</td>\n",
       "      <td>-0.275822</td>\n",
       "      <td>-0.266876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>0.398663</td>\n",
       "      <td>0.523662</td>\n",
       "      <td>0.638807</td>\n",
       "      <td>0.744236</td>\n",
       "      <td>0.832567</td>\n",
       "      <td>0.538486</td>\n",
       "      <td>0.564302</td>\n",
       "      <td>0.581011</td>\n",
       "      <td>0.597674</td>\n",
       "      <td>0.441541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370770</td>\n",
       "      <td>-0.408097</td>\n",
       "      <td>-0.185217</td>\n",
       "      <td>-0.325494</td>\n",
       "      <td>-0.343373</td>\n",
       "      <td>-0.328294</td>\n",
       "      <td>-0.203126</td>\n",
       "      <td>-0.315719</td>\n",
       "      <td>-0.326104</td>\n",
       "      <td>-0.314282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>0.419290</td>\n",
       "      <td>0.509726</td>\n",
       "      <td>0.593165</td>\n",
       "      <td>0.685492</td>\n",
       "      <td>0.777913</td>\n",
       "      <td>0.483669</td>\n",
       "      <td>0.510993</td>\n",
       "      <td>0.536410</td>\n",
       "      <td>0.564583</td>\n",
       "      <td>0.393016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285770</td>\n",
       "      <td>-0.318548</td>\n",
       "      <td>-0.155317</td>\n",
       "      <td>-0.274822</td>\n",
       "      <td>-0.312119</td>\n",
       "      <td>-0.316411</td>\n",
       "      <td>-0.181363</td>\n",
       "      <td>-0.286298</td>\n",
       "      <td>-0.316182</td>\n",
       "      <td>-0.322671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>0.398764</td>\n",
       "      <td>0.498118</td>\n",
       "      <td>0.583356</td>\n",
       "      <td>0.677779</td>\n",
       "      <td>0.775966</td>\n",
       "      <td>0.481279</td>\n",
       "      <td>0.491659</td>\n",
       "      <td>0.524974</td>\n",
       "      <td>0.571944</td>\n",
       "      <td>0.412262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235725</td>\n",
       "      <td>-0.267054</td>\n",
       "      <td>-0.141380</td>\n",
       "      <td>-0.219369</td>\n",
       "      <td>-0.256553</td>\n",
       "      <td>-0.273690</td>\n",
       "      <td>-0.170996</td>\n",
       "      <td>-0.240285</td>\n",
       "      <td>-0.266193</td>\n",
       "      <td>-0.278110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>0.420213</td>\n",
       "      <td>0.495650</td>\n",
       "      <td>0.571790</td>\n",
       "      <td>0.659049</td>\n",
       "      <td>0.749740</td>\n",
       "      <td>0.485707</td>\n",
       "      <td>0.475930</td>\n",
       "      <td>0.501727</td>\n",
       "      <td>0.539150</td>\n",
       "      <td>0.438294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186706</td>\n",
       "      <td>-0.217181</td>\n",
       "      <td>-0.107740</td>\n",
       "      <td>-0.165642</td>\n",
       "      <td>-0.201059</td>\n",
       "      <td>-0.222898</td>\n",
       "      <td>-0.131329</td>\n",
       "      <td>-0.183113</td>\n",
       "      <td>-0.208774</td>\n",
       "      <td>-0.225284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_dominant_hand_0  x_dominant_hand_1  x_dominant_hand_2  \\\n",
       "sequence_id                                                            \n",
       "1816796431            0.408832           0.519912           0.612159   \n",
       "1816796431            0.398663           0.523662           0.638807   \n",
       "1816796431            0.419290           0.509726           0.593165   \n",
       "1816796431            0.398764           0.498118           0.583356   \n",
       "1816796431            0.420213           0.495650           0.571790   \n",
       "\n",
       "             x_dominant_hand_3  x_dominant_hand_4  x_dominant_hand_5  \\\n",
       "sequence_id                                                            \n",
       "1816796431            0.707576           0.797313           0.494709   \n",
       "1816796431            0.744236           0.832567           0.538486   \n",
       "1816796431            0.685492           0.777913           0.483669   \n",
       "1816796431            0.677779           0.775966           0.481279   \n",
       "1816796431            0.659049           0.749740           0.485707   \n",
       "\n",
       "             x_dominant_hand_6  x_dominant_hand_7  x_dominant_hand_8  \\\n",
       "sequence_id                                                            \n",
       "1816796431            0.532817           0.553556           0.566219   \n",
       "1816796431            0.564302           0.581011           0.597674   \n",
       "1816796431            0.510993           0.536410           0.564583   \n",
       "1816796431            0.491659           0.524974           0.571944   \n",
       "1816796431            0.475930           0.501727           0.539150   \n",
       "\n",
       "             x_dominant_hand_9  ...  z_dominant_hand_11  z_dominant_hand_12  \\\n",
       "sequence_id                     ...                                           \n",
       "1816796431            0.391196  ...           -0.245855           -0.269148   \n",
       "1816796431            0.441541  ...           -0.370770           -0.408097   \n",
       "1816796431            0.393016  ...           -0.285770           -0.318548   \n",
       "1816796431            0.412262  ...           -0.235725           -0.267054   \n",
       "1816796431            0.438294  ...           -0.186706           -0.217181   \n",
       "\n",
       "             z_dominant_hand_13  z_dominant_hand_14  z_dominant_hand_15  \\\n",
       "sequence_id                                                               \n",
       "1816796431            -0.129743           -0.251501           -0.278687   \n",
       "1816796431            -0.185217           -0.325494           -0.343373   \n",
       "1816796431            -0.155317           -0.274822           -0.312119   \n",
       "1816796431            -0.141380           -0.219369           -0.256553   \n",
       "1816796431            -0.107740           -0.165642           -0.201059   \n",
       "\n",
       "             z_dominant_hand_16  z_dominant_hand_17  z_dominant_hand_18  \\\n",
       "sequence_id                                                               \n",
       "1816796431            -0.266530           -0.152852           -0.257519   \n",
       "1816796431            -0.328294           -0.203126           -0.315719   \n",
       "1816796431            -0.316411           -0.181363           -0.286298   \n",
       "1816796431            -0.273690           -0.170996           -0.240285   \n",
       "1816796431            -0.222898           -0.131329           -0.183113   \n",
       "\n",
       "             z_dominant_hand_19  z_dominant_hand_20  \n",
       "sequence_id                                          \n",
       "1816796431            -0.275822           -0.266876  \n",
       "1816796431            -0.326104           -0.314282  \n",
       "1816796431            -0.316182           -0.322671  \n",
       "1816796431            -0.266193           -0.278110  \n",
       "1816796431            -0.208774           -0.225284  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_FOLDER = \"processed_dataset\"\n",
    "\n",
    "df = pd.read_pickle(os.path.join(SAVE_FOLDER, \"data.pkl\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{1816796431: {'phrase': array([ 1,  7,  3, 16, 31, 18, 18, 24, 21, 28, 34, 32, 18,  2,  0,  0,  0,\\n ...\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(os.path.join(SAVE_FOLDER, \"metadata.csv\"), header=0)\n",
    "\n",
    "max_phrase_len = max([len(it) for it in metadata_df.phrase.values])\n",
    "possible_characters = sorted(set.union(*[set(p) for p in metadata_df.phrase.values]))\n",
    "token_map = {c: i+3 for i, c in enumerate(possible_characters)}\n",
    "token_map['P'] = 0 # padding\n",
    "token_map['<'] = 1 # SOS\n",
    "token_map['>'] = 2 # EOS\n",
    "metadata_df.phrase = metadata_df.phrase.apply(lambda it: np.array([token_map[c] for c in '<'+it+'>'+('P'*(max_phrase_len-len(it)))], dtype=np.int32))\n",
    "\n",
    "index = {row[0]: {\"phrase\": row[1], \"signer_id\": row[2]} for row in metadata_df.values}\n",
    "str(index)[:100] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sequence_ids = df.index.unique()\n",
    "\n",
    "# train_ids, temp_ids = train_test_split(sequence_ids, test_size=0.3, random_state=seed)\n",
    "# valid_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=seed)\n",
    "\n",
    "# train_df = df[df.index.isin(train_ids)]\n",
    "# valid_df = df[df.index.isin(valid_ids)]\n",
    "# test_df = df[df.index.isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TransformerDataset(torch.utils.data.Dataset):\n",
    "    # NOTE don't change the padding value as the Transformer still relies on 0\n",
    "    def __init__(self, df, meta_data, seq_len=256, padding_value=0):\n",
    "        self.df = df\n",
    "        self.meta_data = meta_data\n",
    "        self.sequence_ids = df.index.unique()\n",
    "        self.padding_value = padding_value\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence_id = self.sequence_ids[idx]\n",
    "        x_values = torch.tensor(self.df.loc[sequence_id].values, dtype=torch.float32)\n",
    "\n",
    "        # Apply padding if the sequence is shorter than seq_len\n",
    "        if x_values.shape[0] < self.seq_len:\n",
    "            padding_size = self.seq_len - x_values.shape[0]\n",
    "            padding = torch.full((padding_size, x_values.shape[1]), self.padding_value)\n",
    "            x_values = torch.cat([x_values, padding], dim=0)\n",
    "        elif x_values.shape[0] > self.seq_len:\n",
    "            # Truncate the sequence if it's longer than seq_len\n",
    "            x_values = x_values[:self.seq_len]\n",
    "\n",
    "        y_phrase = self.meta_data[sequence_id]['phrase']\n",
    "        return x_values, y_phrase\n",
    "\n",
    "dataset = TransformerDataset(df, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256, 63])\n",
      "tensor([[ 1,  7,  3,  ...,  0,  0,  0],\n",
      "        [ 1,  5,  7,  ...,  0,  0,  0],\n",
      "        [ 1, 13, 12,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 1,  8,  5,  ...,  0,  0,  0],\n",
      "        [ 1,  8,  5,  ...,  0,  0,  0],\n",
      "        [ 1, 26, 14,  ...,  0,  0,  0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# NOTE Refactor DataSet (move huge objects outside) before increasing number of workers\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=0)\n",
    "\n",
    "for it in dataloader:\n",
    "    print(it[0].shape)\n",
    "    print(it[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len, n=10000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        assert d_model % 2 == 0, \"d_model must be even\"\n",
    "        \n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(n) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # NOTE\n",
    "        # register buffer in Pytorch ->\n",
    "        # If you have parameters in your model, which should be saved and restored in the state_dict,\n",
    "        # but not trained by the optimizer, you should register them as buffers.\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Broadcasting mechanism (automatically works for multiple batches even when shapes don't match along batch dim)\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalLandmarkEmbedding(nn.Module):\n",
    "    def __init__(self, len_of_seq, d_model, num_features, num_conv_layers=3, filter_size=11):\n",
    "        super(PositionalLandmarkEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.len_of_seq = len_of_seq\n",
    "\n",
    "        first_conv = nn.Conv1d(in_channels=num_features, out_channels=d_model, kernel_size=filter_size, padding='same')\n",
    "        rest_of_convs = [\n",
    "            nn.Conv1d(in_channels=d_model, out_channels=d_model, kernel_size=filter_size, padding='same')\n",
    "            for _ in range(num_conv_layers-1)\n",
    "        ]\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            first_conv, *rest_of_convs\n",
    "        )\n",
    "        \n",
    "        self.pos_encoding = PositionalEncoding(d_model, len_of_seq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is expected to be of shape (batch_size, seq_len, num_of_features)\n",
    "        # Permute to (batch_size, num_of_features, seq_len) for Conv1D\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # Apply convolutional layers\n",
    "        x = self.conv_block(x)\n",
    "        # Scale the output\n",
    "        x *= math.sqrt(self.d_model)\n",
    "        # Permute back to (batch_size, seq_len, d_model)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoding(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class PositionalGraphEmbedding(nn.Module):\n",
    "    def __init__(self, len_of_seq, d_model, num_features_per_node):\n",
    "        super(PositionalLandmarkEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # TODO experiment with hyperparameters\n",
    "        hidden_dim = 256\n",
    "        self.conv1 = GATConv(num_features_per_node, hidden_dim, heads=1, concat=False)\n",
    "        self.conv2 = GATConv(hidden_dim, d_model, heads=1, concat=False)\n",
    "        \n",
    "        self.pos_encoding = PositionalEncoding(d_model, len_of_seq)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.masked_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.masked_self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, len_of_seq, num_inp_features, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = PositionalLandmarkEmbedding(\n",
    "            len_of_seq=len_of_seq,\n",
    "            d_model=d_model,\n",
    "            num_features=num_inp_features,\n",
    "            num_conv_layers=3,\n",
    "            filter_size=11\n",
    "        )\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = 5000\n",
    "tgt_vocab_size = 5000\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "\n",
    "# Generate random sample data\n",
    "src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
    "tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional lr scheduling as in Attention Is All You Need\n",
    "# class LinearWarmupInverseSquarerootDecay(torch.optim.lr_scheduler.LambdaLR):\n",
    "#     def __init__(self, d_model, warmup_steps=4000, optimizer=None):\n",
    "#         self.d_model = d_model\n",
    "#         self.warmup_steps = warmup_steps\n",
    "#         super(LinearWarmupInverseSquarerootDecay, self).__init__(optimizer, self.lr_lambda)\n",
    "\n",
    "#     def lr_lambda(self, step_num):\n",
    "#         return (self.d_model ** -0.5) * min(step_num ** -0.5 if step_num != 0 else 1e20, step_num * (self.warmup_steps ** -1.5))\n",
    "    \n",
    "# steps = np.arange(0, 10000)\n",
    "# learning_rates = [scheduler.lr_lambda(step) for step in steps]\n",
    "\n",
    "# plt.figure(figsize=(6, 3))\n",
    "# plt.plot(steps, learning_rates, label='Learning Rate')\n",
    "# plt.title('Learning Rate Schedule')\n",
    "# plt.xlabel('Step Number')\n",
    "# plt.ylabel('Learning Rate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# scheduler = LinearWarmupInverseSquarerootDecay(d_model=d_model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0) # ignoring padding\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0)\n",
    "# optimizer = torch.optim.Adam(transformer.parameters())\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = transformer(src_data, tgt_data[:, :-1])\n",
    "    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
